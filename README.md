# Data-science-competition-Feature-Engineering

整理自己在算法比赛中遇到的一些常见好用的特征工程，会说明自己理解的一些使用场景

## 1. 目标编码

* 基于目的标签，对数据中的id类特征以及构造的id类特征进行统计性编码。
* eg.\
    **数据**：用户的年龄，性别，职业等\
    **标签**：用户是否还贷？1 or 0\
    这种情况下，我们就构造目标编码，分析不同年龄人群还贷或者不还贷的比例，作为特征去直接预测。不过这种情况下构造的特征很容易过拟合，因此常常和五折特征搭配使用

## 2. 五折特征

* 出于对防止数据整体有偏以及数据增强减少过拟合等情况的考虑，构造统计类特征时，常常借助五折的方式来构造
* eg.\
    上例中的目标编码，我们在分析不同人群的还贷比例的时候，将训练集分成5份，**其中1份的目标编码，来自另外4份，测试集的目标编码来自这5份**

## 3. 聚类统计特征

* 对类别型特征或者类别型标签做出统计的特征,给这些类别塑造一个轮廓
* eg.\
    推荐系统中,我们可以统计每个用户点击的广告的总个数,娱乐广告的个数等
  
## 4. 词频统计特征

* nlp领域的常用特征，统计一段或者一句话中出现的词的数量。也可以用来统计类别数量比较庞大的类别型特征，比如推荐系统的creative_id，ad_id等
  
## 5. Tfidf特征

* nlp领域的常用特征，跟词频统计的效果类似，不同的时tfidf更能凸显出词在句子中的重要性
* 词频(TF)=某个词在文章中的出现次数\文章的总词数
* 逆文档频率(IDF)=语料库的文档总数\(包含该词的文档数+1)
* TF-IDF=词频(TF)*逆并文档频率

## 6. svd降维做特征

* 矩阵分解, 将onehot之后, 维度过大不好训练的特征进行降维, 然后进行训练

## 7. w2v fasttest deepwalk

* 前两种在nlp领域算是很常见的embedding预训练模型.
* 后者为阿里应用在推荐系统里面预训练id类词向量的模型,与之前传统的只是基于单个用户点击历史训练不同的是,deepwalk,构建了用户的点击交互图,通过随机游走的方式,重新构建了sentences,然后去训练w2v.
